{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8494f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from surprise import Dataset,accuracy,Reader,SVD\n",
    "from surprise.model_selection import cross_validate,train_test_split,GridSearchCV,KFold\n",
    "from surprise.accuracy import rmse\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error\n",
    "\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_colwidth', 1)\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c726203",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df=pd.read_csv(\"processed_data.csv\")\n",
    "reader = Reader(rating_scale=(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5d0f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(model_df[['student_id', 'course_id', 'course_rating']], reader)\n",
    "trainSet,testSet=train_test_split(data,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34de0f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 100, 'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.1}\n",
      "0.9141938937317811\n",
      "0.7468314094272931\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9227  0.9343  0.8855  0.9071  0.9242  0.9148  0.0170  \n",
      "MAE (testset)     0.7504  0.7638  0.7362  0.7285  0.7523  0.7462  0.0125  \n",
      "Fit time          0.03    0.03    0.03    0.03    0.03    0.03    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>r_ui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>489</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.132956</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>1089</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.130993</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>2177</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.109326</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>1682</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.098571</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3599</td>\n",
       "      <td>37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.095102</td>\n",
       "      <td>{'was_impossible': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  iid  r_ui       est                    details\n",
       "350   489   5    5.0   4.132956  {'was_impossible': False}\n",
       "655   1089  38   5.0   4.130993  {'was_impossible': False}\n",
       "1516  2177  5    5.0   4.109326  {'was_impossible': False}\n",
       "1332  1682  11   5.0   4.098571  {'was_impossible': False}\n",
       "280   3599  37   5.0   4.095102  {'was_impossible': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_params = {'n_factors': [100,150],\n",
    "              'n_epochs': [5,10,15],\n",
    "              'lr_all':[0.005,0.01,0.1],\n",
    "              'reg_all':[0.02,0.05,0.1]}\n",
    "\n",
    "grid_search_svd = GridSearchCV(SVD,svd_params,measures=['rmse','mae'], cv=5)\n",
    "grid_search_svd.fit(data)\n",
    "print(grid_search_svd.best_params['rmse'])\n",
    "print(grid_search_svd.best_score['rmse'])\n",
    "print(grid_search_svd.best_score['mae'])\n",
    "\n",
    "algo_grid_search_svd = grid_search_svd.best_estimator['rmse']\n",
    "cross_validate(algo_grid_search_svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "predictions = algo_grid_search_svd.test(testSet)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b061afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8503\n",
      "Validation RMSE: 0.8503209297386507\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation RMSE:\",accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82be4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=5, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "algo = SVD(n_factors=100,n_epochs=50,lr_all=0.1,reg_all=0.1)\n",
    "\n",
    "prec_to_ave = []\n",
    "rec_to_ave = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=3.5)\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    \n",
    "    prec_to_ave.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "    rec_to_ave.append(sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "814c6312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision and Recall averages are 0.7019810720719365 and 0.8262723395599162, respectively\n"
     ]
    }
   ],
   "source": [
    "def make_binary_tpr_fpr(predictions, threshold=3.5):\n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "    pred_df['r_ui'].where(pred_df['r_ui']>threshold, 1, inplace=True)\n",
    "    pred_df['r_ui'].where(pred_df['r_ui']<=threshold, 0, inplace=True)\n",
    "    \n",
    "    pred_df['est'].where(pred_df['est']>threshold, 1, inplace=True)\n",
    "    pred_df['est'].where(pred_df['est']<=threshold, 0, inplace=True)\n",
    "\n",
    "    return pred_df['r_ui'], pred_df['est'], \n",
    "\n",
    "true_r, est = make_binary_tpr_fpr(predictions)\n",
    "\n",
    "precision_average = sum(prec_to_ave)/len(prec_to_ave)\n",
    "recall_average = sum(rec_to_ave)/len(prec_to_ave)\n",
    "\n",
    "print(\"Precision and Recall averages are {0} and {1}, respectively\".format(precision_average, recall_average))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
