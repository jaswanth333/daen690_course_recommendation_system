{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from sqlite3 import connect\n",
    "from surprise import Dataset,accuracy\n",
    "from surprise import Reader\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "import numpy as np\n",
    "from surprise import NMF\n",
    "from surprise import CoClustering\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import SlopeOne\n",
    "from surprise import SVDpp\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.accuracy import rmse as rmse_sp\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_colwidth', 1)\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df=pd.read_csv(\"processed_data.csv\")\n",
    "\n",
    "reader = Reader(rating_scale=(1,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id=1583\n",
    "data = Dataset.load_from_df(model_df[['student_id', 'course_name', 'course_rating']], reader)\n",
    "trainSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_df=pd.DataFrame(model_df['course_name'].unique(),columns=[\"course_name\"])\n",
    "index = pd.Index(range(0, len(course_df.index), 1))\n",
    "course_df[\"course_id\"] = course_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AntiTest set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_testset_user = []\n",
    "inner_uid = trainSet.to_inner_uid(student_id)\n",
    "targetUser = inner_uid #inner_id of the target user\n",
    "user_item_ratings = trainSet.ur[targetUser]\n",
    "fillValue = trainSet.global_mean\n",
    "user_item_ratings = trainSet.ur[inner_uid]\n",
    "user_items = [item for (item,_) in (user_item_ratings)]\n",
    "user_items\n",
    "#filter\n",
    "ratings = trainSet.all_ratings()\n",
    "\n",
    "for iid in trainSet.all_items():\n",
    "    if(iid not in user_items):\n",
    "        anti_testset_user.append((trainSet.to_raw_uid(targetUser),trainSet.to_raw_iid(iid),fillValue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Enrolled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_df.loc[course_df['course_id'].isin(user_items)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Based Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name': 'pearson_baseline',\n",
    "                'user_based': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) KNN Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "knn_basic_algo = KNNBasic(min_k=2,k=10,sim_options=sim_options)\n",
    "\n",
    "cross_validate(knn_basic_algo, data, measures=['RMSE', 'MAE'], cv=1, verbose=True)\n",
    "\n",
    "predictions = knn_basic_algo.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ii) KNN with means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "knn_means_algo = KNNWithMeans(min_k=3,sim_options=sim_options)\n",
    "\n",
    "cross_validate(knn_means_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "predictions = knn_means_algo.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  iii) KNNBaseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization Algos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "svd_algo = SVD(n_factors=150,n_epochs=5,lr_all=0.005,reg_all=0.1)\n",
    "cross_validate(svd_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "predictions = svd_algo.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred['err'] = abs(pred.est - pred.r_ui)\n",
    "best_predictions = pred.sort_values(by='err').head(5)\n",
    "best_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii) SVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "svdpp_algo = SVDpp()\n",
    "cross_validate(svdpp_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "predictions = svdpp_algo.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "svdpp_algo = CoClustering(n_cltr_u=10, n_cltr_i=8, random_state=None)\n",
    "cross_validate(svdpp_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "predictions = svdpp_algo.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "svdpp_algo = SlopeOne()\n",
    "cross_validate(svdpp_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "predictions = svdpp_algo.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) KNN Baseline With Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_baseline_param_grid = {\n",
    "    'bsl_options': {\n",
    "        'method': ['als', 'sgd'],\n",
    "        'reg': [1, 2],\n",
    "    },\n",
    "    'sim_options': {\n",
    "        'min_support': [True],\n",
    "        'user_based': [True],\n",
    "        'min_k':[2]\n",
    "    },\n",
    "}\n",
    "\n",
    "grid_search_knn_baseline = GridSearchCV(KNNBaseline,knn_baseline_param_grid, measures=['rmse','mae'], cv=5)\n",
    "grid_search_knn_baseline.fit(data) \n",
    "print(grid_search_knn_baseline.best_params['rmse'])\n",
    "print(grid_search_knn_baseline.best_score['rmse'])\n",
    "print(grid_search_knn_baseline.best_score['mae'])\n",
    "algo_grid_search_knn_baseline = grid_search_knn_baseline.best_estimator['rmse']\n",
    "cross_validate(algo_grid_search_knn_baseline, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "predictions = algo_grid_search_knn_baseline.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) KNNBasic With Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_basic_params = {\n",
    "    'bsl_options': {\n",
    "        'method': ['als', 'sgd'],\n",
    "        'reg': [1, 2],\n",
    "    },\n",
    "    'sim_options': {\n",
    "        'name': ['msd', 'cosine'],\n",
    "        'user_based': [True],\n",
    "        'min_support': [True],\n",
    "\n",
    "    },\n",
    "}\n",
    "\n",
    "grid_search_knn_basic = GridSearchCV(KNNBasic,knn_basic_params, measures=['rmse','mae'], cv=5)\n",
    "grid_search_knn_basic.fit(data) \n",
    "print(grid_search_knn_basic.best_params['rmse'])\n",
    "print(grid_search_knn_basic.best_score['rmse'])\n",
    "print(grid_search_knn_basic.best_score['mae'])\n",
    "\n",
    "algo_grid_search_knn_basic = grid_search_knn_basic.best_estimator['rmse']\n",
    "cross_validate(algo_grid_search_knn_basic, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "predictions = algo_grid_search_knn_basic.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii) SVD with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_params = {'n_factors': [100,150],\n",
    "              'n_epochs': [5,10,15],\n",
    "              'lr_all':[0.005,0.01,0.1],\n",
    "              'reg_all':[0.02,0.05,0.1]}\n",
    "\n",
    "grid_search_svd = GridSearchCV(SVD,svd_params,measures=['rmse','mae'], cv=5)\n",
    "grid_search_svd.fit(data)\n",
    "print(grid_search_svd.best_params['rmse'])\n",
    "print(grid_search_svd.best_score['rmse'])\n",
    "print(grid_search_svd.best_score['mae'])\n",
    "\n",
    "algo_grid_search_svd = grid_search_svd.best_estimator['rmse']\n",
    "cross_validate(algo_grid_search_svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "predictions = algo_grid_search_svd.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv) SVDpp with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svdpp_params = {'n_factors': [100,150],\n",
    "              'n_epochs': [5,10,15],\n",
    "              'lr_all':[0.005,0.01,0.1],\n",
    "              'reg_all':[0.02,0.05,0.1]}\n",
    "\n",
    "grid_search_svdpp = GridSearchCV(SVDpp,svdpp_params,measures=['rmse','mae'], cv=5)\n",
    "grid_search_svdpp.fit(data)\n",
    "print(grid_search_svdpp.best_params['rmse'])\n",
    "print(grid_search_svdpp.best_score['rmse'])\n",
    "print(grid_search_svdpp.best_score['mae'])\n",
    "\n",
    "algo_grid_search_svdpp = grid_search_svdpp.best_estimator['rmse']\n",
    "cross_validate(algo_grid_search_svdpp, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "predictions = algo_grid_search_svdpp.test(anti_testset_user)\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred.sort_values(by=['est'],ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df=student_df.groupby('course_name')['course_rating'].mean().reset_index().rename(columns={'course_rating':'avg_rating'})\n",
    "rating_df.rename(columns = {'course_name':'iid'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = []\n",
    "ytrue = []\n",
    "for i in range(len(predictions)):\n",
    "    ypred.append(predictions[i].est)\n",
    "    ytrue.append(predictions[i].r_ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(ytrue, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().set_figwidth(30)\n",
    "plt.figure().set_figheight(5)\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(data=course_df, x=\"iid\", y=\"est\")\n",
    "sns.scatterplot(data=course_df, x=\"iid\", y=\"avg_rating\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().set_figwidth(30)\n",
    "plt.figure().set_figheight(5)\n",
    "plt.xticks(rotation=90)\n",
    "sns.scatterplot(data=course_df, x=\"avg_rating\", y=\"est\")\n",
    "#sns.lineplot(data=pred, x=\"iid\", y=\"r_ui\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "\n",
    "algorithms = [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]\n",
    "\n",
    "print (\"Attempting: \", str(algorithms), '\\n\\n\\n')\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    print(\"Starting: \" ,str(algorithm))\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    # results = cross_validate(algorithm, data, measures=['RMSE','MAE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    print(\"Done: \" ,str(algorithm), \"\\n\\n\")\n",
    "\n",
    "print ('\\n\\tDONE\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
